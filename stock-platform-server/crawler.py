import os
import re
import datetime
import time
import requests
import json
from bs4 import BeautifulSoup
from groq import Groq 
import OpenDartReader
from supabase import create_client

# ê³µí¬ íƒìš• ì§€ìˆ˜ ê³„ì‚° íŒŒì¼ ì„í¬íŠ¸
try:
    import fg_index_calc 
except ImportError:
    fg_index_calc = None

# 1. í†µí•© ë¶„ì„ ë° ìƒì„¸ ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
DISCLOSURE_PROMPT_TEMPLATE = """
# Role
You are a professional financial analyst. 

# Language
Respond ONLY in KOREAN. (ì ˆëŒ€ë¡œ í•œêµ­ì–´ ì™¸ì˜ ì–¸ì–´(ëŸ¬ì‹œì•„ì–´ ë“±)ë¥¼ ì„ì§€ ë§ˆì„¸ìš”.)

# Task
Analyze the following disclosures for the SAME company and create ONE integrated summary.
You must extract the 'Target Company' and 'Contract Amount' from the provided text.

# Input Data
Company: {corp_name}
Detailed Disclosure Text:
{disclosure_details}

# Constraints
1. **Headline**: Create one integrated English headline.
2. **Key Takeaways (KOREAN)**: 
   - ê° ê³„ì•½ë³„ë¡œ êµ¬ì²´ì  ì •ë³´ ê¸°ìˆ : "1. [ìƒëŒ€ë°© ì´ë¦„]ê³¼ [ê¸ˆì•¡] ê·œëª¨ ê³„ì•½, [ì •ì •ì‚¬ìœ ]"
   - ì‹¤ì œ íšŒì‚¬ ì´ë¦„ê³¼ ê¸ˆì•¡ì„ í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì•„ ëª…ì‹œí•˜ì„¸ìš”. (ëª¨í˜¸í•˜ê²Œ 'company'ë¼ ì ì§€ ë§ˆì„¸ìš”.)
3. **Sentiment**: Overall tone score from -1.0 to 1.0.
4. **JSON Format**: Output strictly in JSON.

# Output Format (JSON)
{{
  "headline": "Integrated Headline",
  "summary": ["1. [ìƒëŒ€ë°©] [ê¸ˆì•¡] ìƒì„¸ ë‚´ìš©", "2. [ìƒëŒ€ë°©] [ê¸ˆì•¡] ìƒì„¸ ë‚´ìš©", "ì¢…í•© ë¶„ì„"],
  "sentiment_score": 0.0,
  "impact_analysis": "íˆ¬ìì ì˜í–¥ ë¶„ì„"
}}
"""

IMPORTANT_KEYWORDS = [
    'ê³µê¸‰ê³„ì•½', 'ìœ ìƒì¦ì', 'ë¬´ìƒì¦ì', 'ì‹¤ì ë°œí‘œ', 'ì˜ì—…ì‹¤ì ', 'ë‹¨ì¼íŒë§¤', 
    'ì¸ìˆ˜', 'í•©ë³‘', 'M&A', 'íŠ¹í—ˆ', 'ì‹ ì œí’ˆ', 'ìµœëŒ€ì£¼ì£¼ë³€ê²½', 'ìê¸°ì£¼ì‹ì·¨ë“', 'í˜„ê¸ˆë°°ë‹¹',
    'ë¶ˆì„±ì‹¤ê³µì‹œ', 'ê´€ë¦¬ì¢…ëª©', 'ìƒì¥íì§€', 'ê³µì‹œë²ˆë³µ'
]

DART_KEY = os.environ.get("DART_API_KEY")
GROQ_KEY = os.environ.get("GROQ_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

client = Groq(api_key=GROQ_KEY)
dart = OpenDartReader(DART_KEY)
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def get_market_indices():
    print("--- Fetching Market Indices ---")
    try:
        urls = {
            "KOSPI": "https://finance.naver.com/sise/sise_index.naver?code=KOSPI",
            "KOSDAQ": "https://finance.naver.com/sise/sise_index.naver?code=KOSDAQ",
            "USD/KRW": "https://finance.naver.com/marketindex/"
        }
        headers = {"User-Agent": "Mozilla/5.0"}
        results = {}
        for name, url in urls.items():
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            node = soup.select_one("#now_value") if name in ["KOSPI", "KOSDAQ"] else soup.select_one(".value")
            if node: results[name] = node.get_text(strip=True)

        for name, val in results.items():
            if val and val != "---":
                row = supabase.table("market_indices").select("history").eq("name", name).execute()
                hist = json.loads(row.data[0].get('history', '[]')) if row.data else []
                clean_val = float(val.replace(',', ''))
                hist.append(clean_val)
                if len(hist) > 10: hist = hist[-10:]
                supabase.table("market_indices").upsert({
                    "name": name, 
                    "current_val": val, 
                    "history": json.dumps(hist)
                }, on_conflict="name").execute()
    except Exception as e:
        print(f"âŒ Index Error: {e}")

def analyze_disclosure():
    print("=== K-Market Insight Data Pipeline Start ===")
    get_market_indices()
    if fg_index_calc:
        fg_index_calc.update_fear_greed_idx()
    
    today = datetime.datetime.now().strftime('%Y%m%d')
    try:
        df = dart.list(start=today, end=today)
    except Exception as e:
        print(f"âŒ DART Error: {e}")
        return

    if df is None or df.empty: return

    # 2ë²ˆ í•´ê²°: ì¢…ëª©ë³„ ê·¸ë£¹í™” (ë¹„ì¸ ë¡œì…€ 3ê±´ ë“±ì„ í•˜ë‚˜ë¡œ ë¬¶ìŒ)
    grouped = {}
    for _, row in df.iterrows():
        code = row.get('stock_code')
        if not code: continue
        if code not in grouped: grouped[code] = []
        grouped[code].append(row)

    for code, rows in grouped.items():
        # ì¤‘ìš” í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê³µì‹œë§Œ í•„í„°ë§
        targets = [r for r in rows if any(kw in r['report_nm'] for kw in IMPORTANT_KEYWORDS)]
        if not targets: continue

        corp_name = targets[0]['corp_name']
        rep_rcept_no = targets[0]['rcept_no']

        # ì¤‘ë³µ ì²´í¬ (ëŒ€í‘œ ë²ˆí˜¸ ê¸°ì¤€)
        check = supabase.table("disclosure_insights").select("id").eq("rcept_no", rep_rcept_no).execute()
        if check.data: continue

        print(f"ğŸ¯ í†µí•© ë¶„ì„ ì¤‘: {corp_name} ({len(targets)}ê±´)")
        
        # 2ë²ˆ í•´ê²°: ê³µì‹œ ì›ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê¸ˆì•¡, ìƒëŒ€ë°© ì •ë³´ íŒŒì•…ìš©)
        full_text_context = ""
        for t in targets:
            try:
                doc = dart.document(t['rcept_no'])
                # HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ì œ (ì•ë¶€ë¶„ 2500ì)
                clean_text = re.sub('<[^<]+?>', '', doc)
                clean_text = re.sub(r'\s+', ' ', clean_text).strip()[:2500]
                full_text_context += f"\n[ê³µì‹œì œëª©: {t['report_nm']}]\n{clean_text}\n"
            except:
                full_text_context += f"\n[ê³µì‹œì œëª©: {t['report_nm']}] (ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨)\n"

        try:
            # 3ë²ˆ í•´ê²°: í•œêµ­ì–´ ë‹µë³€ ê°•ì œ í”„ë¡¬í”„íŠ¸ ì ìš©
            final_prompt = DISCLOSURE_PROMPT_TEMPLATE.format(
                corp_name=corp_name, 
                disclosure_details=full_text_context
            )
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ ê¸ˆìœµ ì „ë¬¸ê°€ì•¼. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ê³ , ê³„ì•½ ìƒëŒ€ë°©ê³¼ ê¸ˆì•¡ì„ ì •í™•íˆ ê¸°ì¬í•´."},
                    {"role": "user", "content": final_prompt}
                ],
                response_format={"type": "json_object"}
            )
            ai_res = json.loads(response.choices[0].message.content)
            
            sentiment = "POSITIVE" if ai_res.get('sentiment_score', 0) > 0.1 else \
                        "NEGATIVE" if ai_res.get('sentiment_score', 0) < -0.1 else "NEUTRAL"

            # 2ë²ˆ í•´ê²°: í†µí•©ëœ ì œëª©ìœ¼ë¡œ ì €ì¥
            combined_title = targets[0]['report_nm']
            if len(targets) > 1:
                combined_title += f" ì™¸ {len(targets)-1}ê±´"

            supabase.table("disclosure_insights").upsert({
                "corp_name": corp_name, 
                "stock_code": code,
                "report_nm": combined_title, 
                "ai_summary": "\n".join(ai_res.get('summary', [])),
                "sentiment": sentiment, 
                "rcept_no": rep_rcept_no,
                "created_at": datetime.datetime.now().isoformat()
            }).execute()
            
        except Exception as e:
            print(f"âŒ AI Error for {corp_name}: {e}")

if __name__ == "__main__":
    analyze_disclosure()