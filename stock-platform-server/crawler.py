import os
import re
import datetime
import time
import requests
import json
from bs4 import BeautifulSoup
from groq import Groq 
import OpenDartReader
from supabase import create_client

# 1. ë‰´ìŠ¤ ë¸Œë¦¬í•‘ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë³´ë‚´ì£¼ì‹  í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš© ë°˜ì˜)
DISCLOSURE_PROMPT_TEMPLATE = """
# Role
You are a professional financial analyst for Global Investors.

# Task
Analyze the following Korean Public Disclosure and create a structured summary.
Extract facts and rewrite them clearly.

# Input Data
Disclosure Title: {disclosure_title}

# Constraints
1. **Headline**: Create a catchy English headline (under 10 words).
2. **Key Takeaways**: Summarize the 3 most important facts in KOREAN (Bullet points).
3. **Sentiment**: Analyze the tone. Score from -1.0 (Very Negative) to 1.0 (Very Positive).
4. **Impact**: Explain WHY this matters to an investor in 1 sentence (KOREAN).
5. **JSON Format**: Output strictly in JSON format.

# Output Format (JSON)
{{
  "headline": "{disclosure_title}",
  "summary": ["ìš”ì•½1", "ìš”ì•½2", "ìš”ì•½3"],
  "sentiment_score": 0.0,
  "impact_analysis": "íˆ¬ìžìž ì˜í–¥ ë¶„ì„ ë‚´ìš©",
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
}}
"""

# 2. AI ë¶„ì„ì„ ì‹¤í–‰í•  ì¤‘ìš” í‚¤ì›Œë“œ ì •ì˜ (ì´ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ AI í˜¸ì¶œ ì•ˆ í•¨)
IMPORTANT_KEYWORDS = [
    'ê³µê¸‰ê³„ì•½', 'ìœ ìƒì¦ìž', 'ë¬´ìƒì¦ìž', 'ì‹¤ì ë°œí‘œ', 'ì˜ì—…ì‹¤ì ', 'ë‹¨ì¼íŒë§¤', 
    'ì¸ìˆ˜', 'í•©ë³‘', 'M&A', 'íŠ¹í—ˆ', 'ì‹ ì œí’ˆ', 'ìµœëŒ€ì£¼ì£¼ë³€ê²½', 'ìžê¸°ì£¼ì‹ì·¨ë“', 'í˜„ê¸ˆë°°ë‹¹'
]

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
DART_KEY = os.environ.get("DART_API_KEY")
GROQ_KEY = os.environ.get("GROQ_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
groq_client = Groq(api_key=GROQ_KEY)
dart = OpenDartReader(DART_KEY)
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)


def get_market_indices():
    print("--- Fetching Market Indices from Naver Finance ---")
    try:
        url = "https://finance.naver.com/"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        res = requests.get(url, headers=headers)
        res.raise_for_status() # ì ‘ì† ì„±ê³µ ì—¬ë¶€ í™•ì¸
        soup = BeautifulSoup(res.text, 'html.parser')

        # 1. KOSPI & KOSDAQ ìˆ˜ì§‘ (ID ìš°ì„  íƒìƒ‰ í›„ í´ëž˜ìŠ¤ ë³´ì¡° íƒìƒ‰)
        kospi_val = soup.find("span", id="KOSPI_now")
        if not kospi_val:
            kospi_val = soup.select_one(".lg_area .kospi_area .num_quot .num")
            
        kosdaq_val = soup.find("span", id="KOSDAQ_now")
        if not kosdaq_val:
            kosdaq_val = soup.select_one(".lg_area .kosdaq_area .num_quot .num")

        # 2. í™˜ìœ¨ ìˆ˜ì§‘ (í™˜ìœ¨ì€ êµ¬ì¡°ê°€ ìžì£¼ ë°”ë€Œë¯€ë¡œ í…ìŠ¤íŠ¸ íŒ¨í„´ìœ¼ë¡œ íƒìƒ‰)
        usd_val = None
        exchange_area = soup.select_one(".group_sub .on")
        if exchange_area:
            usd_val = exchange_area.select_one(".num")
        
        # 3. ë°ì´í„° ì •ì œ (ì‰¼í‘œ ë° ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°)
        def clean_val(node):
            if node:
                text = node.get_text(strip=True)
                # ìˆ«ìž, ë§ˆì¹¨í‘œ, ì‰¼í‘œë§Œ ë‚¨ê¸°ê³  ì œê±°
                return re.sub(r'[^\d.,]', '', text)
            return None

        indices = [
            ("KOSPI", clean_val(kospi_val)),
            ("KOSDAQ", clean_val(kosdaq_val)),
            ("USD/KRW", clean_val(usd_val))
        ]

        # 4. DB ì—…ë°ì´íŠ¸ ë° ë¡œê·¸ ì¶œë ¥
        for name, val in indices:
            if val and len(val) > 1: # ê°’ì´ ìœ íš¨í•  ë•Œë§Œ
                supabase.table("market_indices").upsert(
                    {"name": name, "current_val": val},
                    on_conflict="name"
                ).execute()
                print(f"âœ… {name} ì‹¤ì‹œê°„ ìˆ˜ì§‘ ì„±ê³µ: {val}")
            else:
                print(f"âŒ {name} ìˆ˜ì§‘ ì‹¤íŒ¨: ê²°ê³¼ê°€ ë¹ˆ ê°’ìž…ë‹ˆë‹¤. (ê¸°ì¡´ DB ê°’ ìœ ì§€)")

    except Exception as e:
        print(f"âŒ ì§€ìˆ˜ ìˆ˜ì§‘ ì¤‘ ì‹œìŠ¤í…œ ì—ëŸ¬: {e}")

def analyze_disclosure():
    print("=== K-Market Insight Data Pipeline Start ===")
    
    # 1. ì§€ìˆ˜ ìˆ˜ì§‘ ìš°ì„  ì‹¤í–‰ (ê°€ìž¥ ì¤‘ìš”)
    get_market_indices()
    
    # 2. ì˜¤ëŠ˜ ë‚ ì§œì˜ ì „ì²´ ê³µì‹œ ê°€ì ¸ì˜¤ê¸°
    today = datetime.datetime.now().strftime('%Y%m%d')
    print(f"--- Fetching ALL Disclosures for {today} ---")
    
    try:
        # íŠ¹ì • ê¸°ì—…ì´ ì•„ë‹Œ ì „ì²´ ê³µì‹œ ëª©ë¡ì„ ê°€ì ¸ì˜´
        df = dart.list(start=today, end=today)
    except Exception as e:
        print(f"âŒ DART Fetch Error: {e}")
        return

    if df is None or df.empty:
        print("No disclosures found today.")
        return

    # 3. ë°ì´í„° í•„í„°ë§ ë° AI ë¶„ì„
    # ë„ˆë¬´ ë§Žì€ í˜¸ì¶œì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ìƒìœ„ 20ê°œ ì •ë„ë§Œ ë¨¼ì € ì²´í¬ (í•„ìš”ì‹œ ì¡°ì •)
    for idx, row in df.head(20).iterrows():
        title = row.get('report_nm', '')
        corp_name = row.get('corp_name', '')
        rcept_no = row.get('rcept_no')

        # [í•„í„°ë§ 1] ì¢…ëª© ì½”ë“œê°€ ì—†ëŠ” ê³µì‹œ(ë¹„ìƒìž¥ ë“±) ì œì™¸
        if not row.get('stock_code'):
            continue

        # [í•„í„°ë§ 2] ì´ë¯¸ ì²˜ë¦¬ëœ ê³µì‹œì¸ì§€ í™•ì¸
        check = supabase.table("disclosure_insights").select("id").eq("rcept_no", rcept_no).execute()
        if check.data:
            continue

        # [í•„í„°ë§ 3] ì¤‘ìš” í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
        is_important = any(kw in title for kw in IMPORTANT_KEYWORDS)
        
        if is_important:
            print(f"ðŸŽ¯ ì¤‘ìš” ê³µì‹œ ë¶„ì„ ì‹œìž‘: [{corp_name}] {title}")
            try:
                time.sleep(2) # Groq API ì•ˆì •ì„±ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                
                # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                final_prompt = DISCLOSURE_PROMPT_TEMPLATE.format(
                    disclosure_title=title
                )

                # Groq AI í˜¸ì¶œ
                completion = groq_client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[
                        {"role": "system", "content": "You are a professional financial analyst. Return ONLY JSON."},
                        {"role": "user", "content": final_prompt}
                    ],
                    response_format={"type": "json_object"}
                )

                # AI ê²°ê³¼ íŒŒì‹±
                ai_res = json.loads(completion.choices[0].message.content)
                
                # ê°ì„± ë¶„ì„ í…ìŠ¤íŠ¸ ë³€í™˜
                sentiment_label = "POSITIVE" if ai_res.get('sentiment_score', 0) > 0.1 else \
                                  "NEGATIVE" if ai_res.get('sentiment_score', 0) < -0.1 else "NEUTRAL"

                # DB ì €ìž¥ ë°ì´í„°
                save_data = {
                    "corp_name": corp_name,
                    "stock_code": row.get('stock_code'),
                    "report_nm": title,
                    "ai_summary": "\n".join(ai_res.get('summary', ["ìš”ì•½ ìƒì„± ì‹¤íŒ¨"])),
                    "sentiment": sentiment_label,
                    "rcept_no": rcept_no,
                    "created_at": datetime.datetime.now().isoformat()
                }
                
                supabase.table("disclosure_insights").upsert(save_data).execute()
                print(f"âœ… AI ë¶„ì„ ë° ì €ìž¥ ì™„ë£Œ: {corp_name}")

            except Exception as e:
                print(f"âŒ AI Analysis Error for {corp_name}: {e}")
        else:
            # ì¤‘ìš”í•˜ì§€ ì•Šì€ ê³µì‹œëŠ” ë¶„ì„ ì—†ì´ ê±´ë„ˆëœ€ (ì¿¼í„° ì ˆì•½)
            print(f"â© ì¼ë°˜ ê³µì‹œ íŒ¨ìŠ¤: {title}")

if __name__ == "__main__":
    analyze_disclosure()