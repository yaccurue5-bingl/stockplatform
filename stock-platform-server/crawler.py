import os
import re
import datetime
import time
import requests
import json
from bs4 import BeautifulSoup
from groq import Groq 
import OpenDartReader
from supabase import create_client
# ê³µí¬ íƒìš• ì§€ìˆ˜ ê³„ì‚° íŒŒì¼ ìž„í¬íŠ¸
try:
    import fg_index_calc 
except ImportError:
    fg_index_calc = None

# 1. ë‰´ìŠ¤ ë¸Œë¦¬í•‘ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
DISCLOSURE_PROMPT_TEMPLATE = """
# Role
You are a professional financial analyst for Global Investors.

# Task
Analyze the following Korean Public Disclosure and create a structured summary.
Extract facts and rewrite them clearly.

# Input Data
Disclosure Title: {disclosure_title}

# Constraints
1. **Headline**: Create a catchy English headline (under 10 words).
2. **Key Takeaways**: Summarize the 3 most important facts in KOREAN (Bullet points).
3. **Sentiment**: Analyze the tone. Score from -1.0 (Very Negative) to 1.0 (Very Positive).
4. **Impact**: Explain WHY this matters to an investor in 1 sentence (KOREAN).
5. **JSON Format**: Output strictly in JSON format.

# Output Format (JSON)
{{
  "headline": "English Headline Here",
  "summary": ["ìš”ì•½1", "ìš”ì•½2", "ìš”ì•½3"],
  "sentiment_score": 0.0,
  "impact_analysis": "íˆ¬ìžìž ì˜í–¥ ë¶„ì„ ë‚´ìš©",
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
}}
"""

# 2. ì¤‘ìš” í‚¤ì›Œë“œ ì •ì˜ (ë¶ˆì„±ì‹¤ê³µì‹œ ë“± ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ ì¶”ê°€)
IMPORTANT_KEYWORDS = [
    'ê³µê¸‰ê³„ì•½', 'ìœ ìƒì¦ìž', 'ë¬´ìƒì¦ìž', 'ì‹¤ì ë°œí‘œ', 'ì˜ì—…ì‹¤ì ', 'ë‹¨ì¼íŒë§¤', 
    'ì¸ìˆ˜', 'í•©ë³‘', 'M&A', 'íŠ¹í—ˆ', 'ì‹ ì œí’ˆ', 'ìµœëŒ€ì£¼ì£¼ë³€ê²½', 'ìžê¸°ì£¼ì‹ì·¨ë“', 'í˜„ê¸ˆë°°ë‹¹',
    'ë¶ˆì„±ì‹¤ê³µì‹œ', 'ê´€ë¦¬ì¢…ëª©', 'ìƒìž¥íì§€', 'ê³µì‹œë²ˆë³µ'
]

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
DART_KEY = os.environ.get("DART_API_KEY")
GROQ_KEY = os.environ.get("GROQ_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = Groq(api_key=GROQ_KEY)
dart = OpenDartReader(DART_KEY)
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def get_market_indices():
    print("--- Fetching Market Indices with History ---")
    try:
        urls = {
            "KOSPI": "https://finance.naver.com/sise/sise_index.naver?code=KOSPI",
            "KOSDAQ": "https://finance.naver.com/sise/sise_index.naver?code=KOSDAQ",
            "USD/KRW": "https://finance.naver.com/marketindex/"
        }
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
        
        results = {}
        for name, url in urls.items():
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            node = soup.select_one("#now_value") if name in ["KOSPI", "KOSDAQ"] else soup.select_one(".value")
            if node:
                results[name] = node.get_text(strip=True)

        for name, val in results.items():
            if val and val != "---":
                # ížˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ ë¡œì§
                row = supabase.table("market_indices").select("history").eq("name", name).execute()
                hist = json.loads(row.data[0].get('history', '[]')) if row.data else []
                
                clean_val = float(val.replace(',', ''))
                hist.append(clean_val)
                if len(hist) > 10: hist = hist[-10:] # ìµœê·¼ 10ê°œ ìœ ì§€

                supabase.table("market_indices").upsert({
                    "name": name, 
                    "current_val": val, 
                    "history": json.dumps(hist)
                }, on_conflict="name").execute()
                print(f"âœ… {name} updated with history")
    except Exception as e:
        print(f"âŒ Index Fetch Error: {e}")

def analyze_disclosure():
    print("=== K-Market Insight Data Pipeline Start ===")
    get_market_indices()
    
    # ê³µí¬ íƒìš• ì§€ìˆ˜ ê³„ì‚° í˜¸ì¶œ
    if fg_index_calc:
        fg_index_calc.update_fear_greed_idx()
    
    today = datetime.datetime.now().strftime('%Y%m%d')
    try:
        df = dart.list(start=today, end=today)
    except Exception as e:
        print(f"âŒ DART Error: {e}"); return

    if df is None or df.empty:
        print("No disclosures today."); return

    for idx, row in df.head(20).iterrows():
        title, corp_name, rcept_no = row.get('report_nm', ''), row.get('corp_name', ''), row.get('rcept_no')
        if not row.get('stock_code'): continue

        check = supabase.table("disclosure_insights").select("id").eq("rcept_no", rcept_no).execute()
        if check.data: continue

        if any(kw in title for kw in IMPORTANT_KEYWORDS):
            print(f"ðŸŽ¯ Analyzing: {corp_name}")
            try:
                final_prompt = DISCLOSURE_PROMPT_TEMPLATE.format(disclosure_title=title)
                response = client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[
                        {"role": "system", "content": "Return strictly in JSON format."},
                        {"role": "user", "content": final_prompt} # prompt ì˜¤íƒ€ ìˆ˜ì •
                    ],
                    response_format={"type": "json_object"},
                    max_tokens=1024
                )
                ai_res = json.loads(response.choices[0].message.content) # completion ì˜¤íƒ€ ìˆ˜ì •
                
                sentiment = "POSITIVE" if ai_res.get('sentiment_score', 0) > 0.1 else \
                            "NEGATIVE" if ai_res.get('sentiment_score', 0) < -0.1 else "NEUTRAL"

                supabase.table("disclosure_insights").upsert({
                    "corp_name": corp_name, "stock_code": row.get('stock_code'),
                    "report_nm": title, "ai_summary": "\n".join(ai_res.get('summary', [])),
                    "sentiment": sentiment, "rcept_no": rcept_no,
                    "created_at": datetime.datetime.now().isoformat()
                }).execute()
            except Exception as e:
                print(f"âŒ AI Error for {corp_name}: {e}")