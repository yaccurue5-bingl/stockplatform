import os
import re
import datetime
import time
import requests
import json
from bs4 import BeautifulSoup
from groq import Groq 
import OpenDartReader
from supabase import create_client

# 1. ë‰´ìŠ¤ ë¸Œë¦¬í•‘ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë³´ë‚´ì£¼ì‹  í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš© ë°˜ì˜)
DISCLOSURE_PROMPT_TEMPLATE = """
# Role
You are a professional financial analyst for Global Investors.

# Task
Analyze the following Korean Public Disclosure and create a structured summary.
Extract facts and rewrite them clearly.

# Input Data
Disclosure Title: {disclosure_title}

# Constraints
1. **Headline**: Create a catchy English headline (under 10 words).
2. **Key Takeaways**: Summarize the 3 most important facts in KOREAN (Bullet points).
3. **Sentiment**: Analyze the tone. Score from -1.0 (Very Negative) to 1.0 (Very Positive).
4. **Impact**: Explain WHY this matters to an investor in 1 sentence (KOREAN).
5. **JSON Format**: Output strictly in JSON format.

# Output Format (JSON)
{{
  "headline": "{disclosure_title}",
  "summary": ["ìš”ì•½1", "ìš”ì•½2", "ìš”ì•½3"],
  "sentiment_score": 0.0,
  "impact_analysis": "íˆ¬ìžìž ì˜í–¥ ë¶„ì„ ë‚´ìš©",
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
}}
"""

# 2. AI ë¶„ì„ì„ ì‹¤í–‰í•  ì¤‘ìš” í‚¤ì›Œë“œ ì •ì˜ (ì´ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ AI í˜¸ì¶œ ì•ˆ í•¨)
IMPORTANT_KEYWORDS = [
    'ê³µê¸‰ê³„ì•½', 'ìœ ìƒì¦ìž', 'ë¬´ìƒì¦ìž', 'ì‹¤ì ë°œí‘œ', 'ì˜ì—…ì‹¤ì ', 'ë‹¨ì¼íŒë§¤', 
    'ì¸ìˆ˜', 'í•©ë³‘', 'M&A', 'íŠ¹í—ˆ', 'ì‹ ì œí’ˆ', 'ìµœëŒ€ì£¼ì£¼ë³€ê²½', 'ìžê¸°ì£¼ì‹ì·¨ë“', 'í˜„ê¸ˆë°°ë‹¹'
]

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
DART_KEY = os.environ.get("DART_API_KEY")
GROQ_KEY = os.environ.get("GROQ_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = Groq(
    api_key=os.environ.get("GROQ_API_KEY"), # GitHub Secretsì— ì €ìž¥ëœ í‚¤ë¥¼ ê°€ì ¸ì˜´
)
dart = OpenDartReader(DART_KEY)
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)


def get_market_indices():
    print("--- Fetching Market Indices from Naver ---")
    try:
        # KOSPI, KOSDAQ ìˆ˜ì§‘ ì£¼ì†Œ ë¶„ë¦¬ (ë” ì•ˆì •ì )
        urls = {
            "KOSPI": "https://finance.naver.com/sise/sise_index.naver?code=KOSPI",
            "KOSDAQ": "https://finance.naver.com/sise/sise_index.naver?code=KOSDAQ",
            "USD/KRW": "https://finance.naver.com/marketindex/"
        }
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
        
        results = {}
        for name, url in urls.items():
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            if name in ["KOSPI", "KOSDAQ"]:
                node = soup.select_one("#now_value")
            else: # í™˜ìœ¨
                node = soup.select_one(".value")
            
            if node:
                results[name] = node.get_text(strip=True)

        for name, val in results.items():
            if val:
                supabase.table("market_indices").upsert({"name": name, "current_val": val}, on_conflict="name").execute()
                print(f"âœ… {name} ìˆ˜ì§‘ ì„±ê³µ: {val}")
    except Exception as e:
        print(f"âŒ ì§€ìˆ˜ ìˆ˜ì§‘ ì—ëŸ¬: {e}")

def analyze_disclosure():
    print("=== K-Market Insight Data Pipeline Start ===")
    
    # 1. ì§€ìˆ˜ ìˆ˜ì§‘ ìš°ì„  ì‹¤í–‰ (ê°€ìž¥ ì¤‘ìš”)
    get_market_indices()
    
    # 2. ì˜¤ëŠ˜ ë‚ ì§œì˜ ì „ì²´ ê³µì‹œ ê°€ì ¸ì˜¤ê¸°
    today = datetime.datetime.now().strftime('%Y%m%d')
    print(f"--- Fetching ALL Disclosures for {today} ---")
    
    try:
        # íŠ¹ì • ê¸°ì—…ì´ ì•„ë‹Œ ì „ì²´ ê³µì‹œ ëª©ë¡ì„ ê°€ì ¸ì˜´
        df = dart.list(start=today, end=today)
    except Exception as e:
        print(f"âŒ DART Fetch Error: {e}")
        return

    if df is None or df.empty:
        print("No disclosures found today.")
        return

    # 3. ë°ì´í„° í•„í„°ë§ ë° AI ë¶„ì„
    # ë„ˆë¬´ ë§Žì€ í˜¸ì¶œì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ìƒìœ„ 20ê°œ ì •ë„ë§Œ ë¨¼ì € ì²´í¬ (í•„ìš”ì‹œ ì¡°ì •)
    for idx, row in df.head(20).iterrows():
        title = row.get('report_nm', '')
        corp_name = row.get('corp_name', '')
        rcept_no = row.get('rcept_no')

        # [í•„í„°ë§ 1] ì¢…ëª© ì½”ë“œê°€ ì—†ëŠ” ê³µì‹œ(ë¹„ìƒìž¥ ë“±) ì œì™¸
        if not row.get('stock_code'):
            continue

        # [í•„í„°ë§ 2] ì´ë¯¸ ì²˜ë¦¬ëœ ê³µì‹œì¸ì§€ í™•ì¸
        check = supabase.table("disclosure_insights").select("id").eq("rcept_no", rcept_no).execute()
        if check.data:
            continue

        # [í•„í„°ë§ 3] ì¤‘ìš” í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
        is_important = any(kw in title for kw in IMPORTANT_KEYWORDS)
        
        if is_important:
            print(f"ðŸŽ¯ ì¤‘ìš” ê³µì‹œ ë¶„ì„ ì‹œìž‘: [{corp_name}] {title}")
            try:
                time.sleep(2) # Groq API ì•ˆì •ì„±ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                
                # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                final_prompt = DISCLOSURE_PROMPT_TEMPLATE.format(
                    disclosure_title=title
                )

                # crawler.py ë‚´ì˜ AI í˜¸ì¶œ ë¶€ë¶„ (Groq ë˜ëŠ” OpenAI)
                response = client.chat.completions.create( # ì—¬ê¸°ì„œ 'client' ì´ë¦„ì´ ìœ„ì™€ ê°™ì•„ì•¼ í•¨
                   model="llama-3.3-70b-versatile",
                   messages=[
            {"role": "system", "content": "You are a professional financial analyst. Return your answer strictly in JSON format."},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"},
        max_tokens=1024, # í† í°ì„ ë„‰ë„‰ížˆ ì£¼ì–´ ë‹µë³€ì´ ëŠê¸°ì§€ ì•Šê²Œ í•¨
        temperature=0.1  # ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
    )

                # AI ê²°ê³¼ íŒŒì‹±
                ai_res = json.loads(completion.choices[0].message.content)
                
                # ê°ì„± ë¶„ì„ í…ìŠ¤íŠ¸ ë³€í™˜
                sentiment_label = "POSITIVE" if ai_res.get('sentiment_score', 0) > 0.1 else \
                                  "NEGATIVE" if ai_res.get('sentiment_score', 0) < -0.1 else "NEUTRAL"

                # DB ì €ìž¥ ë°ì´í„°
                save_data = {
                    "corp_name": corp_name,
                    "stock_code": row.get('stock_code'),
                    "report_nm": title,
                    "ai_summary": "\n".join(ai_res.get('summary', ["ìš”ì•½ ìƒì„± ì‹¤íŒ¨"])),
                    "sentiment": sentiment_label,
                    "rcept_no": rcept_no,
                    "created_at": datetime.datetime.now().isoformat()
                }
                
                supabase.table("disclosure_insights").upsert(save_data).execute()
                print(f"âœ… AI ë¶„ì„ ë° ì €ìž¥ ì™„ë£Œ: {corp_name}")

            except Exception as e:
                print(f"âŒ AI Analysis Error for {corp_name}: {e}")
        else:
            # ì¤‘ìš”í•˜ì§€ ì•Šì€ ê³µì‹œëŠ” ë¶„ì„ ì—†ì´ ê±´ë„ˆëœ€ (ì¿¼í„° ì ˆì•½)
            print(f"â© ì¼ë°˜ ê³µì‹œ íŒ¨ìŠ¤: {title}")

if __name__ == "__main__":
    analyze_disclosure()