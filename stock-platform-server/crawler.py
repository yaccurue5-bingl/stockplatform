import os
import re
import datetime
import time
import requests
import json
from bs4 import BeautifulSoup
from groq import Groq 
import OpenDartReader
from supabase import create_client

try:
    import fg_index_calc 
except ImportError:
    fg_index_calc = None

# ÏàòÏ†ï: Ïó¨Îü¨ Í≥µÏãúÎ•º ÌÜµÌï© Î∂ÑÏÑùÌïòÍ∏∞ ÏúÑÌïú ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø
DISCLOSURE_PROMPT_TEMPLATE = """
# Role
You are a professional financial analyst.

# Task
Analyze the following multiple disclosures for the SAME company and create ONE integrated summary.
You must distinguish each contract if there are multiple ones.

# Input Data
Company: {corp_name}
Disclosures:
{disclosure_details}

# Constraints
1. **Headline**: Create one integrated English headline (e.g., "Triple Supply Contracts Signed").
2. **Key Takeaways (KOREAN)**: 
   - Íµ¨Ï≤¥Ï†Å Í≥ÑÏïΩ Ï†ïÎ≥¥: "1. [ÏÉÅÎåÄÎ∞©] [Í∏àÏï°] [Ï†ïÏ†ïÏÇ¨Ïú† Î∞è ÌïµÏã¨Ìï≠Î™©]", "2. [ÏÉÅÎåÄÎ∞©] [Í∏àÏï°]..." ÌòïÌÉúÎ°ú ÎÇòÏó¥.
   - Ï†ÑÏ≤¥Ï†ÅÏù∏ Ïû¨Î¨¥Ï†Å ÏòÅÌñ• Î∞è Ìà¨ÏûêÏûê Ïú†ÏùòÏÇ¨Ìï≠ ÏöîÏïΩ.
3. **Sentiment**: Overall tone score from -1.0 to 1.0.
4. **JSON Format**: Output strictly in JSON.

# Output Format (JSON)
{{
  "headline": "Integrated Headline",
  "summary": ["Í≥ÑÏïΩ1: ÏÉÅÏÑ∏ ÎÇ¥Ïö©", "Í≥ÑÏïΩ2: ÏÉÅÏÑ∏ ÎÇ¥Ïö©", "Ï¢ÖÌï© Î∂ÑÏÑù"],
  "sentiment_score": 0.0,
  "impact_analysis": "Ìà¨ÏûêÏûê ÏòÅÌñ• Î∂ÑÏÑù"
}}
"""

IMPORTANT_KEYWORDS = [
    'Í≥µÍ∏âÍ≥ÑÏïΩ', 'Ïú†ÏÉÅÏ¶ùÏûê', 'Î¨¥ÏÉÅÏ¶ùÏûê', 'Ïã§Ï†ÅÎ∞úÌëú', 'ÏòÅÏóÖÏã§Ï†Å', 'Îã®ÏùºÌåêÎß§', 
    'Ïù∏Ïàò', 'Ìï©Î≥ë', 'M&A', 'ÌäπÌóà', 'Ïã†Ï†úÌíà', 'ÏµúÎåÄÏ£ºÏ£ºÎ≥ÄÍ≤Ω', 'ÏûêÍ∏∞Ï£ºÏãùÏ∑®Îìù', 'ÌòÑÍ∏àÎ∞∞Îãπ',
    'Î∂àÏÑ±Ïã§Í≥µÏãú', 'Í¥ÄÎ¶¨Ï¢ÖÎ™©', 'ÏÉÅÏû•ÌèêÏßÄ', 'Í≥µÏãúÎ≤àÎ≥µ'
]

DART_KEY = os.environ.get("DART_API_KEY")
GROQ_KEY = os.environ.get("GROQ_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

client = Groq(api_key=GROQ_KEY)
dart = OpenDartReader(DART_KEY)
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def get_market_indices():
    # ... (Í∏∞Ï°¥ ÏßÄÏàò ÏàòÏßë Î°úÏßÅÍ≥º ÎèôÏùº)
    print("--- Fetching Market Indices ---")
    try:
        urls = {"KOSPI": "https://finance.naver.com/sise/sise_index.naver?code=KOSPI", "KOSDAQ": "https://finance.naver.com/sise/sise_index.naver?code=KOSDAQ", "USD/KRW": "https://finance.naver.com/marketindex/"}
        headers = {"User-Agent": "Mozilla/5.0"}
        results = {}
        for name, url in urls.items():
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            node = soup.select_one("#now_value") if name in ["KOSPI", "KOSDAQ"] else soup.select_one(".value")
            if node: results[name] = node.get_text(strip=True)
        for name, val in results.items():
            if val and val != "---":
                row = supabase.table("market_indices").select("history").eq("name", name).execute()
                hist = json.loads(row.data[0].get('history', '[]')) if row.data else []
                clean_val = float(val.replace(',', ''))
                hist.append(clean_val)
                if len(hist) > 10: hist = hist[-10:]
                supabase.table("market_indices").upsert({"name": name, "current_val": val, "history": json.dumps(hist)}, on_conflict="name").execute()
    except Exception as e: print(f"‚ùå Index Error: {e}")

def analyze_disclosure():
    print("=== K-Market Insight Data Pipeline Start ===")
    get_market_indices()
    if fg_index_calc: fg_index_calc.update_fear_greed_idx()
    
    today = datetime.datetime.now().strftime('%Y%m%d')
    try:
        df = dart.list(start=today, end=today)
    except Exception as e: print(f"‚ùå DART Error: {e}"); return

    if df is None or df.empty: return

    # [ÏàòÏ†ï] ÎèôÏùº Ï¢ÖÎ™© Í≥µÏãú Í∑∏Î£πÌôî Î°úÏßÅ
    grouped = {}
    for _, row in df.iterrows():
        code = row.get('stock_code')
        if not code: continue
        if code not in grouped: grouped[code] = []
        grouped[code].append(row)

    for code, rows in grouped.items():
        # Ï§ëÏöî ÌÇ§ÏõåÎìú Ìè¨Ìï® Í≥µÏãú ÌïÑÌÑ∞ÎßÅ
        targets = [r for r in rows if any(kw in r['report_nm'] for kw in IMPORTANT_KEYWORDS)]
        if not targets: continue

        corp_name = targets[0]['corp_name']
        # Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Í≥µÏãúÏù∏ÏßÄ ÌôïÏù∏ (ÎåÄÌëú rcept_no Í∏∞Ï§Ä)
        rep_rcept_no = targets[0]['rcept_no']
        check = supabase.table("disclosure_insights").select("id").eq("rcept_no", rep_rcept_no).execute()
        if check.data: continue

        print(f"üéØ Group Analyzing: {corp_name} ({len(targets)}Í±¥)")
        
        # [ÏàòÏ†ï] Ïó¨Îü¨ Í≥µÏãúÏùò Ï†úÎ™©Îì§ÏùÑ ÌïòÎÇòÏùò ÌÖçÏä§Ìä∏Î°ú Ìï©Ï≥êÏÑú Ï†ÑÎã¨
        disc_details = ""
        for t in targets:
            disc_details += f"- {t['report_nm']} (Í≥µÏãúÎ≤àÌò∏: {t['rcept_no']})\n"

        try:
            final_prompt = DISCLOSURE_PROMPT_TEMPLATE.format(
                corp_name=corp_name, 
                disclosure_details=disc_details
            )
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": "Return strictly in JSON. Be specific about contract partners and amounts."},
                    {"role": "user", "content": final_prompt}
                ],
                response_format={"type": "json_object"}
            )
            ai_res = json.loads(response.choices[0].message.content)
            
            sentiment = "POSITIVE" if ai_res.get('sentiment_score', 0) > 0.1 else \
                        "NEGATIVE" if ai_res.get('sentiment_score', 0) < -0.1 else "NEUTRAL"

            # DB Ï†ÄÏû• (Ïó¨Îü¨ Í±¥ÏùÑ ÌïòÎÇòÎ°ú ÌÜµÌï©ÌïòÏó¨ Ï†ÄÏû•)
            report_title = targets[0]['report_nm'] + (f" Ïô∏ {len(targets)-1}Í±¥" if len(targets) > 1 else "")
            
            supabase.table("disclosure_insights").upsert({
                "corp_name": corp_name, 
                "stock_code": code,
                "report_nm": report_title, 
                "ai_summary": "\n".join(ai_res.get('summary', [])),
                "sentiment": sentiment, 
                "rcept_no": rep_rcept_no,
                "created_at": datetime.datetime.now().isoformat()
            }).execute()
        except Exception as e:
            print(f"‚ùå AI Error for {corp_name}: {e}")

if __name__ == "__main__":
    analyze_disclosure()