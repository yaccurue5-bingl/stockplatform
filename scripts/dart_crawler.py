import os
import requests
import time
from datetime import datetime, timedelta
from supabase import create_client, Client
import urllib3
import logging
import hashlib
import re
import zipfile
import io
import xml.etree.ElementTree as ET

# SSL ê²½ê³  ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# DART API ì„¸ì…˜ (ì—°ê²° ì¬ì‚¬ìš© + í—¤ë” ì„¤ì •)
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
    "Accept": "application/json, application/xml, application/zip, */*",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept-Encoding": "gzip, deflate, br",
    "Connection": "keep-alive",
})
session.verify = False

url = os.environ.get("NEXT_PUBLIC_SUPABASE_URL") # URL í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥
key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")
supabase: Client = create_client(url, key)

def generate_hash_key(corp_code: str, rcept_no: str) -> str:
    """ê³µì‹œ hash key ìƒì„±"""
    return hashlib.sha256(f"{corp_code}_{rcept_no}".encode()).hexdigest()

def is_disclosure_processed(corp_code: str, rcept_no: str) -> bool:
    """ì´ë¯¸ ì²˜ë¦¬ëœ ê³µì‹œì¸ì§€ í™•ì¸"""
    try:
        hash_key = generate_hash_key(corp_code, rcept_no)
        result = supabase.table("disclosure_hashes") \
            .select("id") \
            .eq("hash_key", hash_key) \
            .gt("expires_at", datetime.now().isoformat()) \
            .execute()
        return len(result.data) > 0
    except Exception as e:
        logger.warning(f"í•´ì‹œ í™•ì¸ ì‹¤íŒ¨ (ì²˜ë¦¬ ì§„í–‰): {e}")
        return False

def get_clean_content(rcept_no, max_retries=3):
    """ZIP ì••ì¶• í•´ì œ, ìƒì„¸ ì—ëŸ¬ ë¡œê¹… ë° ì •ë°€ ì •ì œ ë¡œì§ í†µí•© (014 ì—ëŸ¬ ì¬ì‹œë„ í¬í•¨)"""
    dart_key = os.environ.get("DART_API_KEY")
    if not dart_key:
        logger.error("DART_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    content_url = f"https://opendart.fss.or.kr/api/document.xml?crtfc_key={dart_key}&rcept_no={rcept_no}"

    for attempt in range(1, max_retries + 1):
        time.sleep(3.0)

        try:
            response = session.get(content_url, timeout=30)

            if response.status_code == 200:
                # 1. ì •ìƒì ì¸ ZIP íŒŒì¼ ì‘ë‹µì¸ ê²½ìš° (PKë¡œ ì‹œì‘)
                if response.content.startswith(b'PK'):
                    try:
                        with zipfile.ZipFile(io.BytesIO(response.content)) as z:
                            xml_name = z.namelist()[0]
                            with z.open(xml_name) as f:
                                raw_text = f.read().decode('utf-8', errors='ignore')

                        # 2. ì •ë°€ ì •ì œ ë¡œì§ (Style, Script ë° HTML íƒœê·¸ ì œê±°)
                        clean_text = re.sub(r'<(style|script)[^>]*>.*?</\1>', '', raw_text, flags=re.DOTALL | re.IGNORECASE)
                        clean_text = re.sub(r'<[^>]*>', '', clean_text)

                        # Null ë°”ì´íŠ¸ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°
                        clean_text = clean_text.replace('\x00', '').replace('\u0000', '')
                        # ì—°ì†ëœ ê³µë°± í•˜ë‚˜ë¡œ í†µí•©
                        clean_text = re.sub(r'\s+', ' ', clean_text).strip()

                        return clean_text[:2500]

                    except Exception as zip_err:
                        logger.error(f"ZIP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({rcept_no}): {zip_err}")
                        return "CONTENT_NOT_AVAILABLE"

                # 3. ZIPì´ ì•„ë‹Œ ê²½ìš° (DART ì—ëŸ¬ XML ì‘ë‹µ)
                else:
                    response_text = response.text
                    dart_status = None
                    dart_message = None

                    if "<?xml" in response_text:
                        try:
                            root = ET.fromstring(response_text)
                            dart_status = root.find('status').text if root.find('status') is not None else None
                            dart_message = root.find('message').text if root.find('message') is not None else None
                        except Exception:
                            pass

                    # 014(íŒŒì¼ ë¯¸ì¡´ì¬) ë˜ëŠ” 020(ìš”ì²­ ì œí•œ ì´ˆê³¼): ì¬ì‹œë„ ëŒ€ìƒ
                    if dart_status in ("014", "020") and attempt < max_retries:
                        wait_time = 3.0 * attempt
                        logger.warning(f"[ì‹œë„ {attempt}/{max_retries}] {rcept_no} ìƒíƒœ {dart_status}: {dart_message} -> {wait_time}ì´ˆ í›„ ì¬ì‹œë„")
                        time.sleep(wait_time)
                        continue

                    if dart_status:
                        logger.warning(f"{rcept_no} ìˆ˜ì§‘ ë¶ˆê°€ - DART ì‘ë‹µ [ìƒíƒœ: {dart_status}] [ë©”ì‹œì§€: {dart_message}]")
                    else:
                        logger.warning(f"{rcept_no} ìˆ˜ì§‘ ë¶ˆê°€ (ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ í˜•ì‹)")

                    return "CONTENT_NOT_AVAILABLE"

        except requests.exceptions.ConnectionError as e:
            if attempt < max_retries:
                wait_time = 3.0 * attempt
                logger.warning(f"[ì‹œë„ {attempt}/{max_retries}] {rcept_no} ì—°ê²° ì˜¤ë¥˜ -> {wait_time}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                time.sleep(wait_time)
                continue
            logger.warning(f"ë³¸ë¬¸ ìˆ˜ì§‘ ì¤‘ ì—°ê²° ì˜¤ë¥˜ ({rcept_no}): {e}")
            return "CONTENT_NOT_AVAILABLE"
        except Exception as e:
            logger.warning(f"ë³¸ë¬¸ ìˆ˜ì§‘ ì¤‘ ì‹œìŠ¤í…œ ì—ëŸ¬ ë°œìƒ ({rcept_no}): {e}")
            return "CONTENT_NOT_AVAILABLE"

    return None

def run_crawler():
    today = datetime.now().strftime('%Y%m%d')
    dart_key = os.environ.get("DART_API_KEY")
    api_url = f"https://opendart.fss.or.kr/api/list.json?crtfc_key={dart_key}&bgnde={today}&endde={today}&page_count=100"

    logger.info(f"ğŸ“¡ DART ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {today}")

    # ... (ë°ì´í„° í˜¸ì¶œë¶€ ìƒëµ) ...
    try:
        res = session.get(api_url, timeout=30)
        data = res.json()
    except Exception as e:
        logger.error(f"âŒ DART API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return

    if data.get("status") == "000":
        count = 0
        for item in data.get("list", []):
            # ... (ì¤‘ë³µ ì²´í¬ ë° ë°ì´í„° ì •ë¦¬ ìƒëµ) ...
            rcept_no = item.get("rcept_no")
            corp_code = item.get("corp_code", "").strip()
            
            if not corp_code or is_disclosure_processed(corp_code, rcept_no):
                continue
            
            # ì •ì œëœ ë³¸ë¬¸ ì¶”ì¶œ í•¨ìˆ˜ í˜¸ì¶œ (ë‚´ë¶€ì—ì„œ sleep + ì¬ì‹œë„ ì²˜ë¦¬)
            content = get_clean_content(rcept_no)

            payload = {
                "rcept_no": rcept_no,
                "corp_code": corp_code,
                "corp_name": item.get("corp_name"),
                "stock_code": item.get("stock_code", "").strip(),
                "rcept_dt": item.get("rcept_dt"),
                "report_nm": item.get("report_nm"),
                "content": content, # ì •ì œëœ í…ìŠ¤íŠ¸ ë˜ëŠ” ë§ˆí‚¹ê°’
                "analysis_status": "pending",
                "created_at": datetime.now().isoformat()
            }

            try:
                supabase.table("disclosure_insights").upsert(payload, on_conflict="rcept_no").execute()
                # (í•´ì‹œ ê¸°ë¡ ë¡œì§ ìƒëµ)
                count += 1
                logger.info(f"âœ… [{count}] {item.get('corp_name')} ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    run_crawler()