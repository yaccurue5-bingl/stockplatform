import os
import json
import logging
import time
from datetime import datetime
from typing import List, Dict, Any
from groq import Groq  # Groq ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from supabase import create_client, Client

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
# Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
groq_client = Groq(api_key=GROQ_API_KEY)

class AIAnalyst:
    def __init__(self):
        # ì‚¬ìš©ì ì œê³µ í”„ë¡¬í”„íŠ¸ë¥¼ Groq(Llama 3 ë“±)ì— ìµœì í™”
        self.system_prompt = """
        You are a top-tier financial analyst for the Korean Stock Market.
        Analyze the given disclosure/news and provide a structured JSON response.

        # Rules:
        1. Headline: Catchy English headline (under 10 words).
        2. Summary: 3 factual bullet points in English.
        3. Sentiment Score: A float between -1.0 (Very Negative) and 1.0 (Very Positive).
        4. Importance: 'High', 'Medium', or 'Low'.
        5. Analysis: Brief impact on stock price.

        # Response Format (Strict JSON):
        {
          "headline": "string",
          "summary": ["string", "string", "string"],
          "sentiment_score": float,
          "importance": "string",
          "impact_analysis": "string"
        }
        """

    def analyze_content(self, corp_name: str, title: str) -> Dict[str, Any]:
        """Groq APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰"""
        try:
            # Llama 3 70B ëª¨ë¸ì€ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë©° Groqì—ì„œ ë§¤ìš° ë¹ ë¦…ë‹ˆë‹¤.
            chat_completion = groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": f"Company: {corp_name}\nTitle: {title}"}
                ],
                model="llama3-70b-8192", # ë˜ëŠ” llama3-8b-8192
                response_format={"type": "json_object"}
            )
            
            return json.loads(chat_completion.choices[0].message.content)
        except Exception as e:
            logger.error(f"Groq Analysis Error: {e}")
            return None

def process_disclosures():
    analyst = AIAnalyst()
    
    # 1. ë¶„ì„ë˜ì§€ ì•Šì€ ê³µì‹œ ë°ì´í„° ì¡°íšŒ
    res = supabase.table("disclosure_insights").select("*").is_("ai_summary", "null").limit(5).execute()
    items = res.data

    if not items:
        logger.info("âœ… No new content to analyze.")
        return

    for item in items:
        logger.info(f"ğŸ” Analyzing: [{item['corp_name']}] {item['report_nm']}")
        
        # 2. AI ë¶„ì„ ì‹¤í–‰
        result = analyst.analyze_content(item['corp_name'], item['report_nm'])
        
        if result:
            # 3. DB ì—…ë°ì´íŠ¸
            update_payload = {
                "ai_summary": "\n".join(result.get("summary", [])),
                "sentiment": "Positive" if result.get("sentiment_score", 0) > 0.1 else ("Negative" if result.get("sentiment_score", 0) < -0.1 else "Neutral"),
                "sentiment_score": result.get("sentiment_score"),
                "importance": result.get("importance"),
                "updated_at": datetime.now().isoformat()
            }
            
            supabase.table("disclosure_insights").update(update_payload).eq("id", item['id']).execute()
            logger.info(f"âœ… DB Updated for {item['corp_name']}")
        
        # Groqì€ ì†ë„ê°€ ë§¤ìš° ë¹ ë¥´ì§€ë§Œ Rate Limit ë°©ì§€ë¥¼ ìœ„í•´ ì§§ê²Œ ëŒ€ê¸°
        time.sleep(0.5)

if __name__ == "__main__":
    process_disclosures()