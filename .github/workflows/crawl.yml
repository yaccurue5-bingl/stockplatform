name: Stock Data Crawler

on:
  schedule:
    - cron: '*/15 * * * *' # 15분마다 실행
  workflow_dispatch: # 수동 실행 버튼 활성화

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10' # 하이픈(-) 확인 완료

    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 supabase python-dotenv

    - name: Run Crawler
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      # 파일 경로를 폴더명/파일명으로 정확히 지정합니다.
      run: python stock-platform-server/crawler.py