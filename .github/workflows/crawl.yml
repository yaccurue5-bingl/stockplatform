name: Stock Data Crawler

on:
  schedule:
    - cron: '*/15 * * * *' # 15분마다 실행
  workflow_dispatch: # 수동 실행 버튼 활성화

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10' # 하이픈(-) 확인 완료

    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 supabase python-dotenv

    - name: Run Crawler
      working-directory: ./stock-platform-server  # 이 폴더 안으로 들어가서 실행해라
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: python crawler.py